---
title: "Tests of fitSHOW method"
author: "Feiyu Zhu"
date: 
link-citations: true
output: 
  pdf_document:
    number_sections: true
    fig_caption: true
vignette: >
  %\VignetteIndexEntry{test}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, out.width = '80%', fig.align='center')
suppressMessages(require(realPSD))
# suppressMessages(require(tidyverse))
suppressMessages(require(optimCheck))
# suppressMessages(require(minpack.lm)) # for nonlinear LS optim
suppressMessages(require(pracma)) # for NLS optimization
source("../tests/dontrun/fitSHOW.R")
```

# Check the empirical PSD matches up with the analytic one.

First we list some physical constants which will be used to generate a single random dataset.

```{r, constants}
# ---------- SHO model parameters ----------
Time  <- 5                   # Total time, second
fs <- 1e7                    # Sampling frequency, Hz
f0 <- 33553                  # Resonance frequency, Hz
Q_vec <- c(1, 10, 100, 500)  # Quality factors, unitless
k  <- 0.172                  # Cantilever stiffness, N/m
Kb <- 1.381e-23              # Boltzmann's constant, (m2*kg)/(s2*K)
Temp <- 298                  # Temperature, K
Const <- 1e30                # unit conversion, 1 m2 = 1e30 fm2
Aw <- 19000/Const            # White noise psd, m2/Hz 
```

Then we set the frequency domain as $f_0 \pm f_0/\sqrt{2}$, i.e.,

```{r, freq_domain}
f_lb <- f0 - f0/sqrt(2) # frequency lower bound
f_ub <- f0 + f0/sqrt(2) # frequency upper bound
fseq <- seq(from = f_lb, to = f_ub, by = 1/Time) # frequency domain, Hz
```

By the result of Theorem 1, we can simulate the periodogram values and smooth them by binning with bin size to be 100.

```{r, sim_periodogram}
bin_size <- 100
# create a function to wrap the simualtion routine
sim_period <- function(fseq, f0, fs, Q, k, Kb, Temp, 
  Aw, unit_conversion = FALSE, bin_size = 100) {
  # analytic psd values, unit m2/Hz
  psd <- psdSHO(fseq, f0, Q, k, Kb, Temp, unit_conversion) + Aw
  # number of frequencies
  nf <- length(fseq) 
  # simulate exponential random variables
  sim_exp <- rexp(nf, rate = 1)
  # empirical psd (periodogram values)
  Y <- sim_exp * psd * fs
  # smoothed empirical psd (by binning)
  Ybar <- binning(Y, bin_size = bin_size)
  return(Ybar)
}
# frequency domain sequence after binning
fbar <- binning(fseq, bin_size = bin_size)
```

Finally we can plot the smoothed periodogram and superimpose the analytic PSD in one figure (on log-log scale) for $Q = 1, 10, 100, 500$ respectively.

```{r, psd_fig_cap, echo = FALSE}
caption <- rep(NA, length(Q_vec))
for(ii in 1:length(Q_vec)) {
  caption[ii] <- paste0("Empirical smoothed periodogram v.s. analytic PSD of SHOW (Q = ", Q_vec[ii], ").")
}
```

```{r, psd, fig.cap = caption}
for(ii in 1:length(Q_vec)) {
  plot(x = fbar, y = sim_period(fseq, f0, fs, Q_vec[ii], k, Kb, Temp, 
    Aw, FALSE, bin_size)/fs, 
    xlab = "frequency (Hz)", ylab = expression(paste("PSD (", m^2/Hz, ")")),
    type = "l", lwd = 0.3, log = "xy")
  lines(x = fbar, y = psdSHO(fbar, f0, Q_vec[ii], k, Kb, Temp, FALSE) + Aw, 
    col = "red")
  legend("topright",
    legend = c("Empirical", "Analytic"), 
    col = c("black", "red"),
    bty = "n", # no box around the legend
    cex = 0.8, # size of the text,
    lwd = 1
  )
}
```

As we can see from Figure \ref{fig:psd1} ~ \ref{fig:psd4}, the simulated periodogram basically matches up with the analytic PSD, which ensures that our simulation of the periodogram by using Theorem 1 does its job.

# Check the MLE estimation/optimization is correct.

## Does `optim` find the minima?

```{r, check_mle_cap, echo = FALSE}
caption_mle <- rep(NA, length(Q_vec))
for(ii in 1:length(Q_vec)) {
  Q <- Q_vec[ii]
  gamma <- f0*Q
  sig2 <- Kb*Temp/(k*pi*f0*Q) 
  Rw <- Aw/sig2
  caption_mle[ii] <- paste0("MLE optim check when Q = ", Q, ". The true parameters are ", 
    "f0 = ", f0, 
    ", gamma = ", gamma,
    ", Rw = ", format(round(Rw, 2), nsmall = 2))
}
```

We can use `optimCheck` to check the "projection plot" of each parameter to see if the minimization of negative log-likelihood works. If we set the initial parameter values to their true values (even with some small random noise added) and choose `method = BFGS`, the optimization usually works for $Q = 1, 10, 100$, as shown in Figure \ref{fig:check_mle_optim1} ~ \ref{fig:check_mle_optim3}. For $Q = 500$, the optimization sometimes cannot find the minimum, see Figure \ref{fig:check_mle_optim4}.

We should notice that if the initial parameter values supplied to `optim` are far from their true values, the optimization usually fail to converge (for any $Q$).

```{r, param_init}
# set the initial parameter values for each Q
phi_list <- lapply(1:length(Q_vec), function(ii) {
  Q <- Q_vec[ii]
  sig2 <- Kb*Temp/(k*pi*f0*Q) # variance, unit: m2/Hz
  Rw <- Aw/sig2 # re-parameterization, note we input Aw with unit fm2/Hz
  phi <- c(f0 + rnorm(1, 0, sqrt(f0)/10), 
    f0*Q + rnorm(1, 0, sqrt(f0*Q)/10), 
    Rw + rnorm(1,0,Rw/10)) 
  # phi <- c(f0, f0*Q, Rw)
  # optimCheck would fail if we adopt a purely random initial phi
  # phi <- runif(3, min = 0, max = 1e5)
})
```

```{r, get_tau, echo = FALSE}
# define get_tau()
get_tau <- function(phi, method) {
  if (method == "lp") {
    gz <- TMB::MakeADFun(data = list(model_name = "SHOWFit",
                                    method = "LP_zeta",
                                    fbar = matrix(fbar),
                                    Zbar = matrix(Zbar),
                                    fs = fs),
                        parameters = list(phi = matrix(0, 3, 1)),
                        silent = TRUE, DLL = "realPSD_TMBExports")
    zeta <- gz$fn(phi)
    exp(zeta)
  } else if (method == "nls") {
    gt <- TMB::MakeADFun(data = list(model_name = "SHOWFit",
                                    method = "NLS_tau",
                                    fbar = matrix(fbar),
                                    Ybar = matrix(Ybar),
                                    fs = fs),
                        parameters = list(phi = matrix(0, 3, 1)),
                        silent = TRUE, DLL = "realPSD_TMBExports")
    gt$fn(phi)
  } else if (method == "mle") {
    gt <- TMB::MakeADFun(data = list(model_name = "SHOWFit",
                                    method = "MLE_tau",
                                    f = matrix(fseq),
                                    Y = matrix(Y),
                                    fs = fs),
                        parameters = list(phi = matrix(0, 3, 1)),
                        silent = TRUE, DLL = "realPSD_TMBExports")
    gt$fn(phi)
  } else {
    stop("method should be chosen from lp, nls and mle.")
  }
}
```

```{r check_mle_optim, fig.cap = caption_mle}
# check the optimization process for each Q
for(ii in 1:length(Q_vec)) {
  Q <- Q_vec[ii]
  # ---------- setup ----------
  # number of frequencies
  nf <- length(fseq) 
  # analytic psd values, unit fm2/Hz
  psd <- psdSHO(fseq, f0, Q, k, Kb, Temp, unit_conversion = FALSE) + Aw
  # simulate exponential random variables
  set.seed(123)
  sim_exp <- rexp(nf, rate = 1)
  # empirical psd (periodogram values)
  Y <- sim_exp * psd * fs
  # TMB model
  obj <- TMB::MakeADFun(data = list(model_name = "SHOWFit",
                                        method = "MLE_nlp",
                                        f = matrix(fseq),
                                        Y = matrix(Y),
                                        fs = fs),
                            parameters = list(phi = matrix(0, 3, 1)),
                            silent = TRUE, DLL = "realPSD_TMBExports")
  # optimization
  opt <- optim(par = phi_list[[ii]], fn = obj$fn, gr = obj$gr,
    method = "BFGS", 
    control = list(maxit = 2000))
  # ---------- check optim ----------
  optim_proj(fun = obj$fn, xsol = opt$par, maximize = FALSE,
    xnames = c("f0", "gamma", "Rw"))
  # ---------- check tau_hat ----------
  phi_hat <- opt$par
  tau_hat <- get_tau(phi_hat, "mle")
  sig2 <- Kb*Temp/(k*pi*f0*Q)
  err <- abs(sig2 - tau_hat)/sig2
  # the difference between sig2 and tau_hat
  print(paste0("MLE: When Q = ", Q, 
    ". The relative error between sig2 and tau_hat is ", 
    paste(round(100*err, 2), "%", sep=""), "."))
}
```

## Is the estimation of $\sigma^2$ accurate enough?

We can also check if the user-defined function `get_tau()` works correctly. The relative error between $\sigma^2$ and the estimation $\hat\tau$ based on the estimated parameter $\hat\phi$ is usually small enough.

## Compare the fitted parametric PSD with the true analytic PSD.

As we can see from Figure \ref{fig:check_mle_psd1} ~ \ref{fig:check_mle_psd4}, the fitted parametric PSD always matches up with the true one.

We should notice that `BFGS` method is usually better than the default Nelder and Mead method under our settings.

```{r, caption_mle_psd, echo = FALSE}
caption_mle_psd <- rep(NA, length(Q_vec))
for(ii in 1:length(Q_vec)) {
  Q <- Q_vec[ii]
  caption_mle_psd[ii] <- paste0("MLE: fitted PSD v.s. analytic PSD when Q = ", Q, ".")
}
```

```{r, check_mle_psd, fig.cap = caption_mle_psd}
# check the optimization process for each Q
for(ii in 1:length(Q_vec)) {
  Q <- Q_vec[ii]
   # simulate exponential random variables
  set.seed(123)
  sim_exp <- rexp(nf, rate = 1) # nf = length(fseq)
  # get estimated parameters from fitSHOW
  param <- fitSHOW(fseq, sim_exp, f0, fs, Q, k, Temp, Aw, bin_size, "mle")
  # calculate the fitted PSD
  psd_hat <- psdSHO(fseq, 
    f0 = param[1],
    Q = param[2],
    k = param[3],
    Kb, Temp, FALSE) + param[4]
  # compare the analytic true PSD with the fitted one
  psd <- psdSHO(fseq, f0, Q, k, Kb, Temp, FALSE) + Aw
  plot(x = fseq, y = psd_hat,
    xlab = "frequency (Hz)", 
    ylab = expression(paste("PSD (", m^2/Hz, ")")),
    type = "l", log = "xy")
  lines(x = fseq, y = psd, col = "red")
  legend("topright",
    legend = c("Fitted", "Analytic"), 
    col = c("black", "red"),
    bty = "n", # no box around the legend
    cex = 0.8, # size of the text,
    lwd = 1
  )
}
```

## MLE check: the conclusion

When we fit the model by using MLE, we should set `method = BFGS` in `optim` and choose the initial parameter values not too far from the true ones. Then the result will be perfect.

# Check the NLS estimation/optimization is correct.

## Does `optim` find the minima?

Similarly, we can do the `optimCheck` to see if the estimated parameters are found near the minima in the NLS method. In our tests, the `BFGS` optimization method usually fails.

Many other nonlinear optimization routines have been tried, finally we chose `nlsr::nlfb` which gives Nash variant of Marquardt nonlinear least squares solution via qr linear solver. In general, the NLS method performs worse than the MLE (even though it converges) as shown by Figure \ref{fig:check_nls_optim1} ~ \ref{fig:check_nls_optim4}. 

We also found out that when the initial parameters are set to be the true values, the results would look much better than those obtained from random initial parameters. (More specifically, the estimated $\hat\sigma^2$ would be more accurate when $Q = 100, 500$.)

```{r, warpper functions, echo = FALSE}
# wrapper function of the vector of residuals for NLS
nls_res <- function(phi, obj) {
  c(obj$simulate(phi)$RES)
} 
# wrapper of nls_res with fixed parameters
nls_res_fixed <- function(phi, obj, fixed_flag, fixed_phi) {
  phi_full <- rep(NA, length(phi))
  phi_full[fixed_flag == TRUE] <- fixed_phi
  phi_full[!fixed_flag] <- phi[!fixed_flag]
  nls_res(phi_full, obj)
}

```

```{r, check_nle_cap, echo = FALSE}
caption_nls <- rep(NA, length(Q_vec))
for(ii in 1:length(Q_vec)) {
  Q <- Q_vec[ii]
  gamma <- f0*Q
  sig2 <- Kb*Temp/(k*pi*f0*Q)
  Rw <- Aw/sig2
  caption_nls[ii] <- paste0("NLS optim check when Q = ", Q, ". The true parameters are ", 
    "f0 = ", f0, 
    ", gamma = ", gamma,
    ", Rw = ", format(round(Rw, 2), nsmall = 2))
}
```

```{r check_nls_optim, fig.cap = caption_nls}
# check the optimization process for each Q
for(ii in 1:length(Q_vec)) {
  Q <- Q_vec[ii]
  # ---------- setup ----------
  # number of frequencies
  nf <- length(fseq) 
  # analytic psd values, unit fm2/Hz
  psd <- psdSHO(fseq, f0, Q, k, Kb, Temp, unit_conversion = FALSE) + Aw
  # simulate exponential random variables
  set.seed(123)
  sim_exp <- rexp(nf, rate = 1)
  # empirical psd (periodogram values)
  Y <- sim_exp * psd * fs
  fbar <- binning(fseq, bin_size = bin_size)
  Ybar <- binning(Y, bin_size = bin_size)
  # TMB model
  obj <- TMB::MakeADFun(data = list(model_name = "SHOWFit",
                                      method = "NLS_nlp",
                                      fbar = matrix(fbar),
                                      Ybar = matrix(Ybar),
                                      fs = fs),
                          parameters = list(phi = matrix(0, 3, 1)),
                          silent = TRUE, DLL = "realPSD_TMBExports")
  # --------- optimization -----------
  phi <- phi_list[[ii]]
  names(phi) <- c("f0", "gamma", "Rw")
  # try to set the initial gamma to be true value (as MATLAB code)
  # optimize Q (gamma), fix f0 and Rw
  opt1 <- pracma::lsqnonlin(fun = nls_res_fixed,
    x0 = phi, 
    obj = obj, fixed_flag = c(1,0,1), fixed_phi = phi[c(1,3)]) 
  # optimize Q and f0, fix Rw
  opt2 <- pracma::lsqnonlin(fun = nls_res_fixed, 
    x0 = opt1$x,
    obj = obj, fixed_flag = c(0,0,1), fixed_phi = phi[3])
  # optimize all three parameters
  opt3 <- pracma::lsqnonlin(fun = nls_res_fixed, 
    x0 = opt2$x,
    obj = obj, fixed_flag = c(0,0,0), fixed_phi = NULL)
  # return phi_hat
  phi_hat <- opt3$x
  # ---------- check optim ----------
  optim_proj(fun = obj$fn, xsol = phi_hat, maximize = FALSE,
    xnames = c("f0", "gamma", "Rw"))
  # ---------- check tau_hat ----------
  tau_hat <- get_tau(phi_hat, "nls")
  sig2 <- Kb*Temp/(k*pi*f0*Q)
  err <- abs(sig2 - tau_hat)/sig2
  # the difference between sig2 and tau_hat
  print(paste0("NLS: When Q = ", Q, 
    ". The relative error between sig2 and tau_hat is ", 
    paste(round(100*err, 2), "%", sep=""), "."))
}
```

## Is the estimation of $\sigma^2$ accurate enough?

The estimatation of $\sigma^2$ are more accurate when we choose the initial parameters to be the true ones.

## Compare the fitted parametric PSD with the true analytic PSD.

The fitted parametric PSD can still match up with its analytic counterpart. 

```{r, caption_nls_psd, echo = FALSE}
caption_nls_psd <- rep(NA, length(Q_vec))
for(ii in 1:length(Q_vec)) {
  Q <- Q_vec[ii]
  caption_nls_psd[ii] <- paste0("NLS: fitted PSD v.s. analytic PSD when Q = ", Q, ".")
}
```

```{r, check_nls_psd, fig.cap = caption_nls_psd}
# check the optimization process for each Q
for(ii in 1:length(Q_vec)) {
  Q <- Q_vec[ii]
   # simulate exponential random variables
  set.seed(123)
  sim_exp <- rexp(nf, rate = 1) # nf = length(fseq)
  # get estimated parameters from fitSHOW
  param <- fitSHOW(fseq, sim_exp, f0, fs, Q, k, Temp, Aw, bin_size, "nls")
  # calculate the fitted PSD
  psd_hat <- psdSHO(fseq, 
    f0 = param[1],
    Q = param[2],
    k = param[3],
    Kb, Temp, FALSE) + param[4]
  # compare the analytic true PSD with the fitted one
  psd <- psdSHO(fseq, f0, Q, k, Kb, Temp, FALSE) + Aw
  plot(x = fseq, y = psd_hat,
    xlab = "frequency (Hz)", 
    ylab = expression(paste("PSD (", m^2/Hz, ")")),
    type = "l", log = "xy")
  lines(x = fseq, y = psd, col = "red")
  legend("topright",
    legend = c("Fitted", "Analytic"), 
    col = c("black", "red"),
    bty = "n", # no box around the legend
    cex = 0.8, # size of the text,
    lwd = 1
  )
}
```

## NLS check: the conclusion

The NLS method is usually biased. But by using `nlsr::nlfb`, we can still get good enough results. The fitted PSD is also acceptable under each $Q$ level.

# Check the LP estimation/optimization is correct.

## Does `optim` find the minima?

```{r, check_lp_cap, echo = FALSE}
caption_lp <- rep(NA, length(Q_vec))
for(ii in 1:length(Q_vec)) {
  Q <- Q_vec[ii]
  gamma <- f0*Q
  sig2 <- Kb*Temp/(k*pi*f0*Q)
  Rw <- Aw/sig2
  caption_lp[ii] <- paste0("LP optim check when Q = ", Q, ". The true parameters are ", 
    "f0 = ", f0, 
    ", gamma = ", gamma,
    ", Rw = ", format(round(Rw, 2), nsmall = 2))
}
```

```{r check_lp_optim, fig.cap = caption_lp}
# bias for LP method
bias <- digamma(bin_size) - log(bin_size)
# check the optimization process for each Q
for(ii in 1:length(Q_vec)) {
  Q <- Q_vec[ii]
  # ---------- setup ----------
  # number of frequencies
  nf <- length(fseq) 
  # analytic psd values, unit fm2/Hz
  psd <- psdSHO(fseq, f0, Q, k, Kb, Temp, unit_conversion = FALSE) + Aw
  # simulate exponential random variables
  set.seed(123)
  sim_exp <- rexp(nf, rate = 1)
  # empirical psd (periodogram values)
  Y <- sim_exp * psd * fs
  fbar <- binning(fseq, bin_size = bin_size)
  Ybar <- binning(Y, bin_size = bin_size)
  Zbar <- log(Ybar)
  # TMB model
  obj <- TMB::MakeADFun(data = list(model_name = "SHOWFit",
                                      method = "LP_nlp",
                                      fbar = matrix(fbar),
                                      Zbar = matrix(Zbar),
                                      fs = fs),
                          parameters = list(phi = matrix(0, 3, 1)),
                          silent = TRUE, DLL = "realPSD_TMBExports")
  # --------- optim BGFS -----------
  opt <- optim(par = phi_list[[ii]], fn = obj$fn, gr = obj$gr,
    method = "BFGS", 
    control = list(maxit = 2000))
  # ---------- check optim ----------
  optim_proj(fun = obj$fn, xsol = opt$par, maximize = FALSE,
    xnames = c("f0", "gamma", "Rw"))
  # ---------- check tau_hat ----------
  phi_hat <- opt$par
  tau_hat <- get_tau(phi_hat, "lp")
  # correct the bias
  tau_hat <- exp(log(tau_hat) - bias)
  sig2 <- Kb*Temp/(k*pi*f0*Q)
  err <- abs(sig2 - tau_hat)/sig2
  # the difference between sig2 and tau_hat
  print(paste0("LP: When Q = ", Q, 
    ". The relative error between sig2 and tau_hat is ", 
    paste(round(100*err, 2), "%", sep=""), "."))
}
```

## Is the estimation of $\sigma^2$ accurate enough?

The estimatation of $\sigma^2$ works very well by setting `method = BFGS` in `optim`.

## Compare the fitted parametric PSD with the true analytic PSD.

As we can see from Figure \ref{fig:check_lp_psd1} ~ \ref{fig:check_lp_psd4}, the fitted PSD always matches up with the analytic one for each level of $Q$.

```{r, caption_lp_psd, echo = FALSE}
caption_lp_psd <- rep(NA, length(Q_vec))
for(ii in 1:length(Q_vec)) {
  Q <- Q_vec[ii]
  caption_lp_psd[ii] <- paste0("LP: fitted PSD v.s. analytic PSD when Q = ", Q, ".")
}
```

```{r, check_lp_psd, fig.cap = caption_lp_psd}
# check the optimization process for each Q
for(ii in 1:length(Q_vec)) {
  Q <- Q_vec[ii]
   # simulate exponential random variables
  set.seed(123)
  sim_exp <- rexp(nf, rate = 1) # nf = length(fseq)
  # get estimated parameters from fitSHOW
  param <- fitSHOW(fseq, sim_exp, f0, fs, Q, k, Temp, Aw, bin_size, "lp")
  # calculate the fitted PSD
  psd_hat <- psdSHO(fseq, 
    f0 = param[1],
    Q = param[2],
    k = param[3],
    Kb, Temp, FALSE) + param[4]
  # compare the analytic true PSD with the fitted one
  psd <- psdSHO(fseq, f0, Q, k, Kb, Temp, FALSE) + Aw
  plot(x = fseq, y = psd_hat,
    xlab = "frequency (Hz)", 
    ylab = expression(paste("PSD (", m^2/Hz, ")")),
    type = "l", log = "xy")
  lines(x = fseq, y = psd, col = "red")
  legend("topright",
    legend = c("Fitted", "Analytic"), 
    col = c("black", "red"),
    bty = "n", # no box around the legend
    cex = 0.8, # size of the text,
    lwd = 1
  )
}
```

## LP check: the conclusion

Out current default settings (by using `optim` and `method = BFGS`) work pretty well for the LP method. 

